{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the place where I experimented with things before commiting them to the package's code.\n",
    "\n",
    "It's also where I put usage code, before I transform those to docs and/or tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# quotes_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['micheleriva_5421', 'englishquotesdatabase_75968']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from saying.base import quotes_src\n",
    "list(quotes_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5421"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = quotes_src['micheleriva_5421']\n",
    "len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'quote': 'Genius is one percent inspiration and ninety-nine percent perspiration.',\n",
       "  'author': 'Thomas Edison'},\n",
       " {'quote': 'You can observe a lot just by watching.', 'author': 'Yogi Berra'},\n",
       " {'quote': 'A house divided against itself cannot stand.',\n",
       "  'author': 'Abraham Lincoln'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75968"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd = quotes_src['englishquotesdatabase_75968']\n",
    "len(dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1', \"'EXTRACTED DATA WITH HTTP:\\\\\\\\THEWEBMINER.COM'\", \"''\", \"'\\\\r'\"],\n",
       " ['2', \"'QUOTE'\", \"'AUTHOR'\", \"'GENRE\\\\r'\"],\n",
       " ['3',\n",
       "  \"'Age is an issue of mind over matter. If you don't mind\",\n",
       "  \"it doesn't matter.'\",\n",
       "  \"'Mark Twain'\",\n",
       "  \"'age\\\\r'\"]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## englishquotesdatabase_75968"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75968"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from saying.base import quotes_src\n",
    "\n",
    "dd = quotes_src['englishquotesdatabase_75968']\n",
    "len(dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['2', \"'QUOTE'\", \"'AUTHOR'\", \"'GENRE\\\\r'\"],\n",
       " [['3',\n",
       "   \"'Age is an issue of mind over matter. If you don't mind\",\n",
       "   \"it doesn't matter.'\",\n",
       "   \"'Mark Twain'\",\n",
       "   \"'age\\\\r'\"],\n",
       "  ['4',\n",
       "   \"'Anyone who stops learning is old\",\n",
       "   \"whether at twenty or eighty. Anyone who keeps learning stays young. The greatest thing in life is to keep your mind young.'\",\n",
       "   \"'Henry Ford'\",\n",
       "   \"'age\\\\r'\"]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd[1], dd[2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from saying.util import (\n",
    "    remove_surrounding_single_quotes, clean_string, dict_of_rows_and_columns, map_fields\n",
    ")\n",
    "\n",
    "\n",
    "columns = list(map(lambda x: remove_surrounding_single_quotes(x).lower(), dd[1]))\n",
    "ddd = list(dict_of_rows_and_columns(dd[2:], columns=columns))\n",
    "\n",
    "ddd = [\n",
    "    {clean_string(k): clean_string(v) for k, v in row.items()} for row in ddd\n",
    "]\n",
    "\n",
    "field_mapper = partial(\n",
    "    map_fields({'quote': 'text', 'author': 'author', 'genre': 'category'})\n",
    ")\n",
    "ddd = list(map(field_mapper, ddd))\n",
    "\n",
    "from saying.util import hash_text\n",
    "\n",
    "\n",
    "def add_id(d: dict, id_func=lambda d: hash_text(d['text']), *, id_field='_id'):\n",
    "    d['_id'] = id_func(d)\n",
    "    return d\n",
    "\n",
    "def iterable_to_dict_items(dicts, key_func=add_id):\n",
    "    for d in dicts:\n",
    "        yield key_func(d), d\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "quotes = list(map(add_id, ddd))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>category</th>\n",
       "      <th>_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'Age is an issue of mind over matter. If you d...</td>\n",
       "      <td>it doesn't matter.'</td>\n",
       "      <td>Mark Twain</td>\n",
       "      <td>f7596f22fafe66a99b30a3abf807ebd8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'Anyone who stops learning is old</td>\n",
       "      <td>whether at twenty or eighty. Anyone who keeps ...</td>\n",
       "      <td>Henry Ford</td>\n",
       "      <td>d157524b525aa2cb596f1c7d66d9e81d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wrinkles should merely indicate where smiles h...</td>\n",
       "      <td>Mark Twain</td>\n",
       "      <td>age</td>\n",
       "      <td>7d69d57616991a78bebbad1bad03ea4c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True terror is to wake up one morning and disc...</td>\n",
       "      <td>Kurt Vonnegut</td>\n",
       "      <td>age</td>\n",
       "      <td>d26ca2ce975e45beb986f0cceb2115e0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A diplomat is a man who always remembers a wom...</td>\n",
       "      <td>Robert Frost</td>\n",
       "      <td>age</td>\n",
       "      <td>3b9e2c14673a8bb9b35f13b592fce46b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75961</th>\n",
       "      <td>'Look</td>\n",
       "      <td>there's no metaphysics on earth like chocolates.'</td>\n",
       "      <td>Fernando Pessoa</td>\n",
       "      <td>8c4291f6956da81515a5c0caec2976d0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75962</th>\n",
       "      <td>Love is when the desire to be desired takes yo...</td>\n",
       "      <td>Henri de Toulouse-Lautrec</td>\n",
       "      <td>valentinesday</td>\n",
       "      <td>4d721a30e5d907fdfd32bcc51dd742d7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75963</th>\n",
       "      <td>I'm a laugh tart. I make no secret of that fact.</td>\n",
       "      <td>Hugh Grant</td>\n",
       "      <td>valentinesday</td>\n",
       "      <td>98fc9ba24726f6fa02017138c6300cd1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75964</th>\n",
       "      <td>I used to be a hopeless romantic - I fell in l...</td>\n",
       "      <td>Jeremy London</td>\n",
       "      <td>valentinesday</td>\n",
       "      <td>a60a9f66ed1f000b262b7cc1d3754385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75965</th>\n",
       "      <td>Working with Julie Andrews is like getting hit...</td>\n",
       "      <td>Christopher Plummer</td>\n",
       "      <td>valentinesday</td>\n",
       "      <td>ab032f501e4afcfdef595236a4c84427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75966 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "0      'Age is an issue of mind over matter. If you d...   \n",
       "1                      'Anyone who stops learning is old   \n",
       "2      Wrinkles should merely indicate where smiles h...   \n",
       "3      True terror is to wake up one morning and disc...   \n",
       "4      A diplomat is a man who always remembers a wom...   \n",
       "...                                                  ...   \n",
       "75961                                              'Look   \n",
       "75962  Love is when the desire to be desired takes yo...   \n",
       "75963   I'm a laugh tart. I make no secret of that fact.   \n",
       "75964  I used to be a hopeless romantic - I fell in l...   \n",
       "75965  Working with Julie Andrews is like getting hit...   \n",
       "\n",
       "                                                  author         category  \\\n",
       "0                                    it doesn't matter.'       Mark Twain   \n",
       "1      whether at twenty or eighty. Anyone who keeps ...       Henry Ford   \n",
       "2                                             Mark Twain              age   \n",
       "3                                          Kurt Vonnegut              age   \n",
       "4                                           Robert Frost              age   \n",
       "...                                                  ...              ...   \n",
       "75961  there's no metaphysics on earth like chocolates.'  Fernando Pessoa   \n",
       "75962                          Henri de Toulouse-Lautrec    valentinesday   \n",
       "75963                                         Hugh Grant    valentinesday   \n",
       "75964                                      Jeremy London    valentinesday   \n",
       "75965                                Christopher Plummer    valentinesday   \n",
       "\n",
       "                                    _id  \n",
       "0      f7596f22fafe66a99b30a3abf807ebd8  \n",
       "1      d157524b525aa2cb596f1c7d66d9e81d  \n",
       "2      7d69d57616991a78bebbad1bad03ea4c  \n",
       "3      d26ca2ce975e45beb986f0cceb2115e0  \n",
       "4      3b9e2c14673a8bb9b35f13b592fce46b  \n",
       "...                                 ...  \n",
       "75961  8c4291f6956da81515a5c0caec2976d0  \n",
       "75962  4d721a30e5d907fdfd32bcc51dd742d7  \n",
       "75963  98fc9ba24726f6fa02017138c6300cd1  \n",
       "75964  a60a9f66ed1f000b262b7cc1d3754385  \n",
       "75965  ab032f501e4afcfdef595236a4c84427  \n",
       "\n",
       "[75966 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(quotes)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12148"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gather_by_id(df, min_count=2):\n",
    "    \"\"\"a dict whose keys are ids and values are the lists of text values\n",
    "     with the same ids\"\"\"\n",
    "    t = df.groupby('_id')['text'].apply(list).to_dict()\n",
    "    return {k: v for k, v in t.items() if len(v) >= min_count}\n",
    "\n",
    "t = gather_by_id(df)\n",
    "len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(t.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>category</th>\n",
       "      <th>_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64208</th>\n",
       "      <td>'In sports</td>\n",
       "      <td>you simply aren't considered a real champion u...</td>\n",
       "      <td>Althea Gibson</td>\n",
       "      <td>006aa8429d0dfcc6da5e3004c2be0d01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64350</th>\n",
       "      <td>'In sports</td>\n",
       "      <td>people reach their peak very early. You have t...</td>\n",
       "      <td>but I'm still doing the work I always wanted t...</td>\n",
       "      <td>006aa8429d0dfcc6da5e3004c2be0d01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64355</th>\n",
       "      <td>'In sports</td>\n",
       "      <td>teams win and individuals don't.'</td>\n",
       "      <td>Fran Tarkenton</td>\n",
       "      <td>006aa8429d0dfcc6da5e3004c2be0d01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             text                                             author  \\\n",
       "64208  'In sports  you simply aren't considered a real champion u...   \n",
       "64350  'In sports  people reach their peak very early. You have t...   \n",
       "64355  'In sports                  teams win and individuals don't.'   \n",
       "\n",
       "                                                category  \\\n",
       "64208                                      Althea Gibson   \n",
       "64350  but I'm still doing the work I always wanted t...   \n",
       "64355                                     Fran Tarkenton   \n",
       "\n",
       "                                    _id  \n",
       "64208  006aa8429d0dfcc6da5e3004c2be0d01  \n",
       "64350  006aa8429d0dfcc6da5e3004c2be0d01  \n",
       "64355  006aa8429d0dfcc6da5e3004c2be0d01  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k, q = next(it)\n",
    "df[df['_id'] == k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"'In sports\",\n",
       " 'author': \"you simply aren't considered a real champion until you have defended your title successfully. Winning it once can be a fluke winning it twice proves you are the best.'\",\n",
       " 'category': 'Althea Gibson',\n",
       " '_id': '006aa8429d0dfcc6da5e3004c2be0d01'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddd[64208]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['64211',\n",
       "  \"'She\",\n",
       "  \"and I'\",\n",
       "  \"'Alice'\",\n",
       "  \"'crypto\\r')\",\n",
       "  '(64353',\n",
       "  \"'Snap\",\n",
       "  'crackle',\n",
       "  \"and pop'\",\n",
       "  \"'Bob'\",\n",
       "  \"'cereal\\r'\"]]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_text = \"\"\"\n",
    "INSERT INTO `quotes`  (id_, quote, author, genre) VALUES\n",
    "\n",
    "(64211,'She, and I', 'Alice', 'crypto\\r'),\n",
    "(64353,'Snap, crackle, and pop','Bob','cereal\\r');\n",
    "\"\"\"\n",
    "\n",
    "from saying.util import extract_sql_data\n",
    "\n",
    "t = extract_sql_data(sql_text)\n",
    "tt = t[0]\n",
    "tt\n",
    "\n",
    "len(t[0])\n",
    "t\n",
    "\n",
    "sql_text = \"\"\"\n",
    "INSERT INTO `quotes`  (id_, quote, author, genre) VALUES\n",
    "\n",
    "(64211,'She, and I', 'Alice', 'crypto\\r'),\n",
    "(64353,'Snap, crackle, and pop','Bob','cereal\\r');\n",
    "\"\"\"\n",
    "\n",
    "table_name, columns, rows = extract_sql_data(sql_text)\n",
    "expected_table_name = 'quotes'\n",
    "expected_columns = ['id_', 'quote', 'author', 'genre']\n",
    "expected_rows = [\n",
    "    ['64211', \"'She, and I'\", \"'Alice'\", \"'crypto\\r')\"],\n",
    "    ['(64353', \"'Snap, crackle, and pop'\", \"'Bob'\", \"'cereal\\r'\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(tt)=1\n",
      "len(tt[0])=16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['64211',\n",
       " \"'In sports\",\n",
       " \"you simply aren't considered a real champion until you have defended your title successfully. Winning it once can be a fluke winning it twice proves you are the best.'\",\n",
       " \"'Althea Gibson'\",\n",
       " \"'sports\\r')\",\n",
       " '(64353',\n",
       " \"'In sports\",\n",
       " \"people reach their peak very early. You have to move on. I don't know if I will ever surpass what I did at the Olympics\",\n",
       " \"but I'm still doing the work I always wanted to do.'\",\n",
       " \"'Greg Louganis'\",\n",
       " \"'sports\\r')\",\n",
       " '(64358',\n",
       " \"'In sports\",\n",
       " \"teams win and individuals don't.'\",\n",
       " \"'Fran Tarkenton'\",\n",
       " \"'sports\\r'\"]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_text = \"\"\"\n",
    "INSERT INTO `quotes`  (id_, quote, author, genre) VALUES\n",
    "(64211,'In sports, you simply aren\\'t considered a real champion until you have defended your title successfully. Winning it once can be a fluke winning it twice proves you are the best.','Althea Gibson','sports\\r'),\n",
    "(64353,'In sports, people reach their peak very early. You have to move on. I don\\'t know if I will ever surpass what I did at the Olympics, but I\\'m still doing the work I always wanted to do.','Greg Louganis','sports\\r'),\n",
    "(64358,'In sports, teams win and individuals don\\'t.','Fran Tarkenton','sports\\r');\n",
    "\"\"\"\n",
    "\n",
    "from saying.util import extract_sql_data\n",
    "import re\n",
    "\n",
    "\n",
    "tt = extract_sql_data(sql_text)\n",
    "# ttt = tt[0]\n",
    "# len(ttt)\n",
    "# print(*ttt, sep='\\n')\n",
    "# tt = sqlparse.split(t)\n",
    "print(f\"{len(tt)=}\")\n",
    "print(f\"{len(tt[0])=}\")\n",
    "tt[0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58773"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from saying.util import hash_text\n",
    "\n",
    "t = {hash_text(d['text']): d for d in ddd}\n",
    "len(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrap - SQL parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('quotes', ['id_', 'quote', 'author', 'genre'], [])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlparse\n",
    "\n",
    "def extract_sql_data(sql_text):\n",
    "    # Parse the SQL text\n",
    "    parsed = sqlparse.parse(sql_text)[0]\n",
    "\n",
    "    # Initialize variables\n",
    "    table_name = \"\"\n",
    "    columns = []\n",
    "    rows = []\n",
    "\n",
    "    # Process each token in the parsed SQL\n",
    "    for token in parsed.tokens:\n",
    "        # Extract table name from 'INSERT INTO' statement\n",
    "        # if token.ttype is sqlparse.tokens.DML and token.value.upper() == 'INSERT':\n",
    "        #     table_name = next(token for token in token.parent.tokens if isinstance(token, sqlparse.sql.Identifier)).get_name()\n",
    "\n",
    "        if token.ttype is sqlparse.tokens.DML and token.value.upper() == 'INSERT':\n",
    "            table_name_token = next((token for token in token.parent.tokens if isinstance(token, sqlparse.sql.Identifier)), None)\n",
    "            if table_name_token is not None:\n",
    "                table_name = table_name_token.get_name()\n",
    "                \n",
    "        # Extract column names\n",
    "        if isinstance(token, sqlparse.sql.IdentifierList):\n",
    "            columns = [identifier.get_name() for identifier in token.get_identifiers()]\n",
    "\n",
    "        # Extract row values\n",
    "        if isinstance(token, sqlparse.sql.Parenthesis):\n",
    "            row_data = str(token).strip('()').split(',')\n",
    "            # Clean up and format the row data\n",
    "            row_data = [value.strip() for value in row_data]\n",
    "            rows.append(tuple(row_data))\n",
    "\n",
    "    return table_name, columns, rows\n",
    "\n",
    "import sqlparse\n",
    "import re\n",
    "\n",
    "def extract_sql_data(sql_text):\n",
    "    # Parse the SQL text\n",
    "    parsed = sqlparse.parse(sql_text)[0]\n",
    "\n",
    "    # Initialize variables\n",
    "    table_name = \"\"\n",
    "    columns = []\n",
    "    rows = []\n",
    "\n",
    "    # Manually extract table name and column names\n",
    "    match = re.search(r\"INSERT INTO `(.+?)`\\s*\\((.+?)\\)\", sql_text)\n",
    "    if match:\n",
    "        table_name = match.group(1)\n",
    "        columns = [col.strip() for col in match.group(2).split(\",\")]\n",
    "\n",
    "    # Process each token in the parsed SQL\n",
    "    for token in parsed.tokens:\n",
    "        # Extract row values\n",
    "        if isinstance(token, sqlparse.sql.Parenthesis):\n",
    "            row_data = str(token).strip('()').split(',')\n",
    "            # Clean up and format the row data\n",
    "            row_data = [value.strip() for value in row_data]\n",
    "            rows.append(tuple(row_data))\n",
    "\n",
    "    return table_name, columns, rows\n",
    "    \n",
    "# Example usage\n",
    "sql_text = \"\"\"\n",
    "INSERT INTO `quotes`  (id_, quote, author, genre) VALUES\n",
    "\n",
    "(64211,'She, and I', 'Alice', 'crypto\\r'),\n",
    "(64353,'Snap, crackle, and pop','Bob','cereal\\r');\n",
    "\"\"\"\n",
    "\n",
    "table_name, columns, rows = extract_sql_data(sql_text)\n",
    "expected_table_name = 'quotes'\n",
    "expected_columns = ['id_', 'quote', 'author', 'genre']\n",
    "expected_rows = [\n",
    "    ('64211', \"'She, and I'\", \"'Alice'\", \"'crypto\\r')\"),\n",
    "    ('64353', \"'Snap, crackle, and pop'\", \"'Bob'\", \"'cereal\\r'\")\n",
    "]\n",
    "# assert (table_name, columns, rows) == (expected_table_name, expected_columns, expected_rows)\n",
    "table_name, columns, rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed = sqlparse.parse(sql_text)[0]\n",
    "\n",
    "# Initialize variables\n",
    "table_name = \"\"\n",
    "columns = []\n",
    "rows = []\n",
    "\n",
    "# Manually extract table name and column names\n",
    "match = re.search(r\"INSERT INTO `(.+?)`\\s*\\((.+?)\\)\", sql_text)\n",
    "if match:\n",
    "    table_name = match.group(1)\n",
    "    columns = [col.strip() for col in match.group(2).split(\",\")]\n",
    "\n",
    "# Process each token in the parsed SQL\n",
    "for token in parsed.tokens:\n",
    "    # Extract row values\n",
    "    if isinstance(token, sqlparse.sql.Values):\n",
    "        row_data = str(token).strip('()').split(',')\n",
    "        # Clean up and format the row data\n",
    "        row_data = [value.strip() for value in row_data]\n",
    "        rows.append(tuple(row_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('VALUES\\n\\n(64211',\n",
       "  \"'She\",\n",
       "  \"and I'\",\n",
       "  \"'Alice'\",\n",
       "  \"'crypto\\r')\",\n",
       "  '(64353',\n",
       "  \"'Snap\",\n",
       "  'crackle',\n",
       "  \"and pop'\",\n",
       "  \"'Bob'\",\n",
       "  \"'cereal\\r'\")]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sqlparse.sql.Values"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(parsed.tokens[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'cursor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[105], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m sql_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124mINSERT INTO `quotes`  (id_, quote, author, genre) VALUES\u001b[39m\n\u001b[1;32m      5\u001b[0m \n\u001b[1;32m      6\u001b[0m \u001b[38;5;124m(64211,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mShe, and I\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAlice\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcrypto\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m),\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124m(64353,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSnap, crackle, and pop\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBob\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcereal\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m);\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 10\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/site-packages/pandas/io/sql.py:654\u001b[0m, in \u001b[0;36mread_sql\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize, dtype_backend, dtype)\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[1;32m    653\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pandas_sql, SQLiteDatabase):\n\u001b[0;32m--> 654\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[43m            \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    657\u001b[0m \u001b[43m            \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[43m            \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    660\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    661\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    665\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    666\u001b[0m         _is_table_name \u001b[38;5;241m=\u001b[39m pandas_sql\u001b[38;5;241m.\u001b[39mhas_table(sql)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/site-packages/pandas/io/sql.py:2326\u001b[0m, in \u001b[0;36mSQLiteDatabase.read_query\u001b[0;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[1;32m   2315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_query\u001b[39m(\n\u001b[1;32m   2316\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2317\u001b[0m     sql,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2324\u001b[0m     dtype_backend: DtypeBackend \u001b[38;5;241m|\u001b[39m Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2325\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Iterator[DataFrame]:\n\u001b[0;32m-> 2326\u001b[0m     cursor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2327\u001b[0m     columns \u001b[38;5;241m=\u001b[39m [col_desc[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m col_desc \u001b[38;5;129;01min\u001b[39;00m cursor\u001b[38;5;241m.\u001b[39mdescription]\n\u001b[1;32m   2329\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/lib/python3.10/site-packages/pandas/io/sql.py:2260\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[0;34m(self, sql, params)\u001b[0m\n\u001b[1;32m   2258\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuery must be a string unless using sqlalchemy.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2259\u001b[0m args \u001b[38;5;241m=\u001b[39m [] \u001b[38;5;28;01mif\u001b[39;00m params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m [params]\n\u001b[0;32m-> 2260\u001b[0m cur \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcon\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcursor\u001b[49m()\n\u001b[1;32m   2261\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2262\u001b[0m     cur\u001b[38;5;241m.\u001b[39mexecute(sql, \u001b[38;5;241m*\u001b[39margs)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'cursor'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sql_text = \"\"\"\n",
    "INSERT INTO `quotes`  (id_, quote, author, genre) VALUES\n",
    "\n",
    "(64211,'She, and I', 'Alice', 'crypto\\r'),\n",
    "(64353,'Snap, crackle, and pop','Bob','cereal\\r');\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(sql_text, con=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table: quotes\n",
      "Columns: []\n",
      "Rows: [('',)]\n"
     ]
    }
   ],
   "source": [
    "import sqlparse\n",
    "\n",
    "def parse_sql_dump(sql_text):\n",
    "    # Parse the SQL dump\n",
    "    parsed = sqlparse.parse(sql_text)\n",
    "\n",
    "    table_name = None\n",
    "    columns_list = []\n",
    "    rows = []\n",
    "\n",
    "    for statement in parsed:\n",
    "        if statement.get_type() == 'CREATE':\n",
    "            # Extract table name\n",
    "            tokens = [token for token in statement.tokens if not token.is_whitespace]\n",
    "            for i, token in enumerate(tokens):\n",
    "                if token.value.upper() == 'TABLE':\n",
    "                    table_name = tokens[i + 1].get_real_name()\n",
    "                elif token.ttype is sqlparse.tokens.Punctuation and token.value == '(':\n",
    "                    # Extract columns\n",
    "                    columns_list = [str(column).strip() for column in tokens[i + 1].get_identifiers()]\n",
    "                    break\n",
    "\n",
    "        elif statement.get_type() == 'INSERT':\n",
    "            # Extract rows\n",
    "            for token in statement.flatten():\n",
    "                if token.value.upper().startswith('VALUES'):\n",
    "                    values_str = token.value[6:].strip()\n",
    "                    rows_str = values_str[1:-1]  # Remove surrounding parentheses\n",
    "                    rows = [tuple(val.strip() for val in row.split(',')) for row in rows_str.split('),(')]\n",
    "\n",
    "    return table_name, columns_list, rows\n",
    "\n",
    "# Example usage\n",
    "sql_text = \"\"\"CREATE TABLE `quotes` (\n",
    "  `id` int(11) NOT NULL AUTO_INCREMENT,\n",
    "  `quote` varchar(800) DEFAULT NULL,\n",
    "  `author` varchar(100) DEFAULT NULL,\n",
    "  `genre` varchar(100) DEFAULT NULL,\n",
    "  PRIMARY KEY (`id`)\n",
    ");\n",
    "INSERT INTO `quotes` VALUES (1, 'Life is what happens...', 'John Lennon', 'life'), (2, 'Get busy living...', 'Stephen King', 'life');\"\"\"\n",
    "\n",
    "from saying.base import quotes_src\n",
    "from dol import Pipe\n",
    "f = Pipe(*quotes_src.funcs['x16bkkamz6rkb78rzt7op_75968'].funcs[:-1])\n",
    "sql_text = f()\n",
    "\n",
    "table_name, columns, rows = parse_sql_dump(sql_text)\n",
    "\n",
    "print(\"Table:\", table_name)\n",
    "print(\"Columns:\", columns)\n",
    "print(\"Rows:\", rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wikimedia quotes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from saying.wikimedia import download_and_process_wiki_data, parse_wikimedia_xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATE: 20231201\n",
      "File ids.ttl already exists. Skipping download.\n",
      "\n",
      "language='en'\n",
      "File /Users/thorwhalen/.config/saying/wikimedia/en/wikidata.sql already exists. Skipping download.\n",
      "File /Users/thorwhalen/.config/saying/wikimedia/en/pages.xml already exists. Skipping download.\n",
      "\n",
      "language='fr'\n",
      "File /Users/thorwhalen/.config/saying/wikimedia/fr/wikidata.sql already exists. Skipping download.\n",
      "File /Users/thorwhalen/.config/saying/wikimedia/fr/pages.xml already exists. Skipping download.\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "download_and_process_wiki_data(('en', 'fr'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'dol' has no attribute 'base'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msaying\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m extract_sql_data\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Example SQL text to be processed\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msaying\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m extract_sql_data, extract_sql_table_rows\n",
      "File \u001b[0;32m~/Dropbox/py/proj/t/saying/saying/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"AI tools for quotes and sayings.\"\"\"\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msaying\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_raw_data\n",
      "File \u001b[0;32m~/Dropbox/py/proj/t/saying/saying/util.py:7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Iterable, Optional, Union\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconfig2py\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_app_data_folder\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgraze\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m graze \u001b[38;5;28;01mas\u001b[39;00m _graze\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhashlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m md5\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n",
      "File \u001b[0;32m~/Dropbox/py/proj/t/graze/graze/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Getting stuff from the internet (and caching locally, automatically)\"\"\"\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgraze\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      4\u001b[0m     DFLT_GRAZE_DIR,\n\u001b[1;32m      5\u001b[0m     Internet,\n\u001b[1;32m      6\u001b[0m     Graze,\n\u001b[1;32m      7\u001b[0m     GrazeWithDataRefresh,\n\u001b[1;32m      8\u001b[0m     graze,\n\u001b[1;32m      9\u001b[0m     url_to_filepath,\n\u001b[1;32m     10\u001b[0m     url_to_contents,\n\u001b[1;32m     11\u001b[0m     preget_print_downloading_message,\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgraze\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m handle_missing_dir\n",
      "File \u001b[0;32m~/Dropbox/py/proj/t/graze/graze/base.py:12\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m partialmethod, partial\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpy2store\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m inner_most_key\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# from py2store.persisters.local_files import ensure_slash_suffix\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdol\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfilesys\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ensure_slash_suffix\n",
      "File \u001b[0;32m~/Dropbox/py/proj/i/py2store/py2store/__init__.py:127\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpy2store\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maccess\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mystores\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ignore_if_module_not_found:\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpy2store\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstores\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01ms3_store\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    128\u001b[0m         S3BinaryStore,\n\u001b[1;32m    129\u001b[0m         S3TextStore,\n\u001b[1;32m    130\u001b[0m         S3PickleStore,\n\u001b[1;32m    131\u001b[0m     )\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m# If you want it, import from mongodol (pip installable) directly\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# with ignore_if_module_not_found:\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m#     from mongodol.stores import (\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m#         MongoAnyKeyStore,\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;66;03m#     )\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ignore_if_module_not_found:\n",
      "File \u001b[0;32m~/Dropbox/py/proj/i/py2store/py2store/stores/s3_store.py:7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcontextlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m suppress\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m suppress(\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m):\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01ms3dol\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01ms3_store\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/Dropbox/py/proj/i/s3dol/s3dol/__init__.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03ms3 (through boto3) with a simple (dict-like or list-like) interface\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01ms3dol\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m S3Dol\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01ms3dol\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m S3Store\n",
      "File \u001b[0;32m~/Dropbox/py/proj/i/s3dol/s3dol/base.py:91\u001b[0m\n\u001b[1;32m     86\u001b[0m     client \u001b[38;5;241m=\u001b[39m session\u001b[38;5;241m.\u001b[39mclient(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms3\u001b[39m\u001b[38;5;124m'\u001b[39m, endpoint_url\u001b[38;5;241m=\u001b[39mendpoint_url)\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m client\n\u001b[1;32m     90\u001b[0m \u001b[38;5;129m@dataclass\u001b[39m\n\u001b[0;32m---> 91\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mBaseS3BucketReader\u001b[39;00m(\u001b[43mdol\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase\u001b[49m\u001b[38;5;241m.\u001b[39mKvReader):\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;124;03m\"\"\"Dict-like interface for AWS S3 buckets\"\"\"\u001b[39;00m\n\u001b[1;32m     94\u001b[0m     client: boto3\u001b[38;5;241m.\u001b[39mclient\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'dol' has no attribute 'base'"
     ]
    }
   ],
   "source": [
    "from saying.util import extract_sql_data\n",
    "\n",
    "# Example SQL text to be processed\n",
    "from saying.util import extract_sql_data, extract_sql_table_rows\n",
    "\n",
    "sql_text = \"\"\"\n",
    "/*!40000 ALTER TABLE `quotes` DISABLE KEYS */;\n",
    "INSERT INTO `quotes` (col1,col2,col3) VALUES \n",
    "(1,'One', 1.0),\n",
    "(2,'Two', 2.0),\n",
    "(3,'Three', 3.0);\n",
    "\"\"\"\n",
    "\n",
    "# Test the function with the example SQL text\n",
    "quotes_data = extract_sql_data(sql_text)\n",
    "\n",
    "# Print the extracted data\n",
    "print(quotes_data)\n",
    "\n",
    "text = sql_text\n",
    "import re\n",
    "insert_statements = re.findall(\n",
    "    (\n",
    "        r\"INSERT INTO \"\n",
    "        \"`[^`]+\"  # table name\n",
    "        \"`.+?\"  # could be nothing, or colmns...\n",
    "        \"VALUES.+?\\((.*?)\\);\"  # statement (rows)\n",
    "    ),\n",
    "    text,\n",
    "    re.DOTALL,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table: quotes\n",
      "Columns: []\n",
      "Rows: [('',)]\n"
     ]
    }
   ],
   "source": [
    "import sqlparse\n",
    "\n",
    "def parse_sql_dump(sql_text):\n",
    "    # Parse the SQL dump\n",
    "    parsed = sqlparse.parse(sql_text)\n",
    "\n",
    "    table_name = None\n",
    "    columns_list = []\n",
    "    rows = []\n",
    "\n",
    "    for statement in parsed:\n",
    "        if statement.get_type() == 'CREATE':\n",
    "            # Extract table name\n",
    "            tokens = [token for token in statement.tokens if not token.is_whitespace]\n",
    "            for i, token in enumerate(tokens):\n",
    "                if token.value.upper() == 'TABLE':\n",
    "                    table_name = tokens[i + 1].get_real_name()\n",
    "                elif token.ttype is sqlparse.tokens.Punctuation and token.value == '(':\n",
    "                    # Extract columns\n",
    "                    columns_list = [str(column).strip() for column in tokens[i + 1].get_identifiers()]\n",
    "                    break\n",
    "\n",
    "        elif statement.get_type() == 'INSERT':\n",
    "            # Extract rows\n",
    "            for token in statement.flatten():\n",
    "                if token.value.upper().startswith('VALUES'):\n",
    "                    values_str = token.value[6:].strip()\n",
    "                    rows_str = values_str[1:-1]  # Remove surrounding parentheses\n",
    "                    rows = [tuple(val.strip() for val in row.split(',')) for row in rows_str.split('),(')]\n",
    "\n",
    "    return table_name, columns_list, rows\n",
    "\n",
    "# Example usage\n",
    "sql_text = \"\"\"CREATE TABLE `quotes` (\n",
    "  `id` int(11) NOT NULL AUTO_INCREMENT,\n",
    "  `quote` varchar(800) DEFAULT NULL,\n",
    "  `author` varchar(100) DEFAULT NULL,\n",
    "  `genre` varchar(100) DEFAULT NULL,\n",
    "  PRIMARY KEY (`id`)\n",
    ");\n",
    "INSERT INTO `quotes` VALUES (1, 'Life is what happens...', 'John Lennon', 'life'), (2, 'Get busy living...', 'Stephen King', 'life');\n",
    "\"\"\"\n",
    "\n",
    "table_name, columns, rows = parse_sql_dump(sql_text)\n",
    "print(\"Table:\", table_name)\n",
    "print(\"Columns:\", columns)\n",
    "print(\"Rows:\", rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(b)=13733779\n",
      "Table: quotes\n",
      "Columns: []\n",
      "len(rows)=1\n"
     ]
    }
   ],
   "source": [
    "from saying.util import graze, graze_urls\n",
    "\n",
    "\n",
    "b = graze(graze_urls['x16bkkamz6rkb78rzt7op_75968'])\n",
    "print(f\"{len(b)=}\")\n",
    "\n",
    "# table_name, columns, rows = parse_sql_dump(b.decode())\n",
    "print(\"Table:\", table_name)\n",
    "print(\"Columns:\", columns)\n",
    "print(f\"{len(rows)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XML parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221768"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "\n",
    "def parse_wikimedia_xml(file_path):\n",
    "    tree = ET.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    quotes_data = []\n",
    "\n",
    "    for page in root.findall('{http://www.mediawiki.org/xml/export-0.10/}page'):\n",
    "        title_elem = page.find('{http://www.mediawiki.org/xml/export-0.10/}title')\n",
    "        text_elem = page.find('{http://www.mediawiki.org/xml/export-0.10/}revision/{http://www.mediawiki.org/xml/export-0.10/}text')\n",
    "\n",
    "        # if title_elem is not None and text_elem is not None:\n",
    "        #     title = title_elem.text\n",
    "        #     text = text_elem.text\n",
    "\n",
    "        #     # Basic parsing for quotes (may need adjustment based on the actual format)\n",
    "        #     quotes = re.findall(r'\\*\\s*\\'\\'(.+?)\\'\\'', text)\n",
    "        #     for quote in quotes:\n",
    "        #         quotes_data.append((title, quote))\n",
    "\n",
    "        if title_elem is not None and text_elem is not None and text_elem.text is not None:\n",
    "            title = title_elem.text\n",
    "            text = text_elem.text\n",
    "\n",
    "            # Basic parsing for quotes (may need adjustment based on the actual format)\n",
    "            quotes = re.findall(r'\\*\\s*\\'\\'(.+?)\\'\\'', text)\n",
    "            for quote in quotes:\n",
    "                quotes_data.append((title, quote))\n",
    "\n",
    "    return quotes_data\n",
    "\n",
    "# Example usage\n",
    "file_path = '/Users/thorwhalen/.config/saying/wikiquotes/en/pages.xml'\n",
    "quotes = parse_wikimedia_xml(file_path)\n",
    "len(quotes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/Users/thorwhalen/.config/saying/wikiquotes/en/pages.xml'\n",
    "from dol import ValueCodecs\n",
    "\n",
    "encode, decode = ValueCodecs.default.xml_etree\n",
    "from pathlib import Path\n",
    "# t = decode(Path(file_path).read_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1485"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from saying.util import hash_text\n",
    "\n",
    "t = set(map(lambda x: hash_text(x['quote']), d))\n",
    "tt = set(map(lambda x: hash_text(x['text']), dd))\n",
    "len(t & tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': '{\\n \"b\": 2\\n}'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dol import ValueCodecs, wrap_kvs\n",
    "from dol.trans import ValueCodec\n",
    "\n",
    "d = {}\n",
    "dd = ValueCodecs.json(indent=True)(d)\n",
    "dd['a'] = {'b': 2}\n",
    "d\n",
    "\n",
    "\n",
    "# ValueCodecs.default.json\n",
    "# import json\n",
    "# json.dumps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'quote': 'Genius is one percent inspiration and ninety-nine percent perspiration.',\n",
       "  'author': 'Thomas Edison'},\n",
       " {'quote': 'You can observe a lot just by watching.', 'author': 'Yogi Berra'},\n",
       " {'quote': 'A house divided against itself cannot stand.',\n",
       "  'author': 'Abraham Lincoln'}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5421"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd = get_raw_data('micheleriva')\n",
    "len(dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5eb63bbbe01eeed093cb22bb8f5acdc3'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hashlib import md5\n",
    "import re\n",
    "\n",
    "non_alphanumeric_re = re.compile(r'\\W+')\n",
    "\n",
    "def lower_alphanumeric(text):\n",
    "    return non_alphanumeric_re.sub(' ', text).strip().lower()\n",
    "\n",
    "def hash_text(text):\n",
    "    \"\"\"Return a hash of the text, ignoring punctuation and capitalization.\n",
    "    \n",
    "    >>> (assert hash_text('Hello, world!') \n",
    "    ...     ==  hash_text('hello world') \n",
    "    ...     == '5eb63bbbe01eeed093cb22bb8f5acdc3'\n",
    "    ... )\n",
    "\n",
    "    \"\"\"\n",
    "    normalized_text = lower_alphanumeric(text)\n",
    "    return md5(normalized_text.encode()).hexdigest()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
